{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " Задание на программирование\n",
    "Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания. После того, как все ответы совпадут, можно будет использовать полученный блокнот для выполнения индивидуального задания.\n",
    "\n",
    "Зададим гиперпараметры модели\n",
    "\n"
   ],
   "id": "66063f50ef28d86e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T21:27:38.224852Z",
     "start_time": "2025-03-26T21:27:38.217820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Гиперпараметры\n",
    "epsilon = 0.05  # Эпсилон для эпсилон-жадной стратегии\n",
    "gamma = 0.9  # Коэффициент дисконтирования\n",
    "random_seed = 2  # Фиксируем сид для воспроизводимости\n",
    "lr_rate = 0.9  # Скорость обучения\n",
    "\n",
    "time_delay = 1  # Задержка при отрисовке игры"
   ],
   "id": "fb950d7ee759f3f4",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр is_slippery=False отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию generate_random_map , для того, чтобы генерировать произвольные карты на основе random_seed .",
   "id": "ef4223fa795f7618"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T21:27:38.248749Z",
     "start_time": "2025-03-26T21:27:38.233748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Функция генерации карты\n",
    "def generate_random_map(size, p, sd):\n",
    "    np.random.seed(sd)\n",
    "    valid = False\n",
    "\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [(0, 0)], set()\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if (r, c) in discovered:\n",
    "                continue\n",
    "            discovered.add((r, c))\n",
    "            for x, y in [(1, 0), (0, 1), (-1, 0), (0, -1)]:\n",
    "                r_new, c_new = r + x, c + y\n",
    "                if 0 <= r_new < size and 0 <= c_new < size:\n",
    "                    if res[r_new][c_new] == 'G':\n",
    "                        return True\n",
    "                    if res[r_new][c_new] not in '#H':\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1 - p])\n",
    "        res[0][0], res[-1][-1] = 'S', 'G'\n",
    "        valid = is_valid(res)\n",
    "\n",
    "    return [\"\".join(row) for row in res]\n",
    "\n",
    "# Создание среды\n",
    "random_map = generate_random_map(size=6, p=0.8, sd=random_seed)\n",
    "maze=random_map\n",
    "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False)\n",
    "print(\"Ваша карта\")\n",
    "env.reset()\n",
    "env.render()"
   ],
   "id": "57966b1d000543e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваша карта\n",
      "\n",
      "\u001B[41mS\u001B[0mFFFFF\n",
      "FFFFFF\n",
      "FFFFHF\n",
      "HFFFFF\n",
      "FFFFFF\n",
      "FFFFFG\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса environment, то есть:\n",
    "\n",
    "action = env.action_space.sample()\n",
    "\n",
    "Задача 1\n",
    "\n",
    "Дополните функцию learn(), чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения"
   ],
   "id": "e1b8c0d1a8388fbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T21:27:38.265744Z",
     "start_time": "2025-03-26T21:27:38.258086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Вывод количества побед и номера игры, когда впервые было одержано 5 побед подряд\n",
    "def choose_action(state):\n",
    "    action=0\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n) #***\n",
    "        #action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "def learn(state, state2, reward, action, done):\n",
    "    #Q-learning\n",
    "    if done:\n",
    "      Q[state, action] = Q[state, action] + lr_rate * (reward - Q[state, action])\n",
    "    else:\n",
    "      Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2, :]) - Q[state, action])"
   ],
   "id": "a62f434ab7ca0401",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задача 2\n",
    "Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд.\n",
    "\n",
    "Поясним, что возвращает функция ```env.step(action)```\n",
    "\n",
    "```state2``` -- следующее состояние\n",
    "\n",
    "```reward``` -- награда\n",
    "\n",
    "```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях."
   ],
   "id": "789efab4a6329ca5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T21:27:41.429360Z",
     "start_time": "2025-03-26T21:27:38.281644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Inititalization\n",
    "wins_arr = [] #delete\n",
    "np.random.seed(random_seed)\n",
    "total_episodes = 10000\n",
    "max_steps = 100\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "min_episode = 0 #delete\n",
    "#Main cycle\n",
    "for episode in tqdm(range(total_episodes)):\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    while t < max_steps:\n",
    "      #delete\n",
    "        if episode > 5 and wins_arr[episode-5] == 1 and wins_arr[episode-4] == 1 and wins_arr[episode-3] == 1 and wins_arr[episode-2] == 1 and wins_arr[episode-1] == 1 and min_episode ==0:\n",
    "          min_episode = episode\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        action = choose_action(state)\n",
    "\n",
    "        state2, reward, done, info = env.step(action)\n",
    "\n",
    "        if t == max_steps:\n",
    "          done = True\n",
    "\n",
    "        learn(state, state2, reward, action, done)\n",
    "\n",
    "        state = state2\n",
    "\n",
    "        if done and reward == 1:\n",
    "          wins_arr.append(1) #record if won\n",
    "          break\n",
    "        if done:\n",
    "          wins_arr.append(0) #record if lost\n",
    "          break\n",
    "\n",
    "#print(\"Таблица ценностей действий\")\n",
    "#print(np.round(Q,2))\n",
    "#Number of wins\n",
    "print('')\n",
    "print(\"Количество побед в серии из 10 000 игр: \", np.sum(wins_arr))\n",
    "#Number of the episode\n",
    "print(\"Пять побед подряд впервые было одержано в игре \",min_episode)"
   ],
   "id": "95ed80f7a1396134",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3187.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Количество побед в серии из 10 000 игр:  9824\n",
      "Пять побед подряд впервые было одержано в игре  81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются.",
   "id": "7c5f51fcb5bc5fdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#@title Отдельная игра после обучения\n",
    "#Just 1 game to check if Q-table fits to win\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def choose_action_one_game(state):\n",
    "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "states=[]\n",
    "t = 0\n",
    "state = env.reset()\n",
    "\n",
    "while(t<1000):\n",
    "  env.render()\n",
    "  time.sleep(time_delay)\n",
    "  clear_output(wait=True)\n",
    "  action = choose_action_one_game(state)\n",
    "  state2, reward, done, info = env.step(action)\n",
    "  #print(reward)\n",
    "  states.append(state)\n",
    "  state = state2\n",
    "  t += 1\n",
    "  if done and reward == 1:\n",
    "    wn=1\n",
    "  if done:\n",
    "    break\n",
    "if wn == 1:\n",
    "  print(\"!!!Победа!!!\")\n",
    "\n"
   ],
   "id": "41f645f64c5efeab",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T21:27:51.643616Z",
     "start_time": "2025-03-26T21:27:51.509536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Построение карты маршрута\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_maze_pic(maze):\n",
    "  maze_pic=[]\n",
    "  for i in range(len(maze)):\n",
    "    row = []\n",
    "    for j in range(len(maze[i])):\n",
    "      if maze[i][j] == 'S':\n",
    "        row.append(0)\n",
    "      if maze[i][j] == 'F':\n",
    "        row.append(0)\n",
    "      if maze[i][j] == 'H':\n",
    "        row.append(1)\n",
    "      if maze[i][j] == 'G':\n",
    "        row.append(0)\n",
    "    maze_pic.append(row)\n",
    "  maze_pic = np.array(maze_pic)\n",
    "  return maze_pic\n",
    "\n",
    "\n",
    "#Make maze fit to plot\n",
    "maze_pic = make_maze_pic(maze)\n",
    "nrows, ncols = maze_pic.shape\n",
    "\n",
    "#Arrays of picture elements\n",
    "rw = np.remainder(states,nrows)\n",
    "cl = np.floor_divide(states,nrows)\n",
    "rw = np.append(rw, [nrows-1])\n",
    "cl = np.append(cl,[ncols-1])\n",
    "\n",
    "#Picture plotting\n",
    "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
    "ax1.clear()\n",
    "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
    "ax1.set_yticklabels([])\n",
    "ax1.grid(True)\n",
    "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
    "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
    "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
    "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
    "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
    "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
    "ax1.imshow(maze_pic, cmap=\"binary\")\n"
   ],
   "id": "b6cd47c911f3e21d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2add6f4a000>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задача 3\n",
    "\n",
    "Дублируйте полученный блокнот и используйте вместо алгоритма Q-обучения алгоритм SARSA. Обратите внимание на то, что в задании требуется изменить количество игр. То есть `total_games = 40000`. Запускать блоки следует последвательно с самого начала (из-за `random_seed`). Отдельно обращаем ваше внимание на то, что при изменении алгоритма с Q-обучения на SARSA модификации подлежит как процесс обучения, так и функция `learn()`. Кроме того, у функции `learn()` должен появиться дополнительный аргумент (следующее действие). Ниже приведен фрагмент кода с пояснениями, как именно нужно модифицировать алгоритм."
   ],
   "id": "24c2f253e3776fc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
